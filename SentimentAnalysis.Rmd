---
title: "Sentiment Analysis"
author: "Gabriele"
date: "27/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Sentiment Analysis
##Twitter US Airline
Given the Twitter 'US Airline Sentiment' Dataset provided on Kaggle we will try to build a machine learning tool to predict whether a given tweetter is associated to a specific sentiment among:

-  Positive

-  Neutral

-  Negative

The project wil be divided in several step. Starting from the raw data we will preprocess them with the de-facto standard techniques and them build a term-document frequency matrix to be used ad learning data.


```{r}
# load packages
library(dplyr)
library(quanteda)
library(ggplot2)
library(wordcloud)
library(caret)
library(Factoshiny)
```


##Import the data
```{r}
data.raw = read.csv("Tweets.csv", header=TRUE,
                    stringsAsFactors = FALSE, )

data.raw %>% summary
data.raw %>% names
data.raw %>% dim
data.raw %>% str
# any missing case?
length(which(!complete.cases(data.raw)))
```
the data show many redundant information that are beyond the goal of this project, so we will discard them, here a list:

- tweet_id

- airline_sentiment_confidence

- negativereason_confidence

- airline_sentiment_gold

- name

- negativereason_gold

- retweet_count

- tweet_coord

- tweet_created

- user_timezone
```{r}
# delete predictors
data.raw = data.raw[,-c(1,3,5,7,8,9,10,12,13,14,15)]
data.raw %>% dim
data.raw %>% names
data.raw %>% str

names(data.raw) = c("Sentiment", "Negative_Reason", "Airline", "Text")
```
Some categorical predictors are of type 'char' while we need them as 'factors', so we perform a cast:
```{r}
# our response variable
data.raw$Sentiment = as.factor(data.raw$Sentiment)
data.raw$Airline =  as.factor(data.raw$Airline)

head(data.raw)
str(data.raw)
```
#Satisfaction rate for Companies
```{r}
# Which and how many distint companies are mentioned?
airline.names = unique(data.raw$Airline)
#print(airline.names)
#length(airline.names)
# 6

# Look at the sentiment for each company
attach(data.raw)

par(mfrow=c(2,3), cex=.7, cex.main=.9)
for( i in airline.names){
    barplot(
        prop.table(table(Sentiment[Airline==i])),
        col=4:6,
        main=paste("Sentiment Distribution \n for",i),
        axes=TRUE,
        las=2
    )
}

detach(data.raw)
```
For all the companies the predominant sentiment is 'negative'; well this could be explained by considering the fact that often, after a positive expirience, customers are not interested to share their experience as much as when they face issues/problems
Anyway both 'Virgin America' and 'Delta' have a much better response.

Now we will have a look at only the negative tweets and we will try to investigate the main cause by means of clustering
```{r}
# pick only the negative tweets
causes.negative.tweets = data.raw[data.raw$Sentiment=="negative",]
# pick the reason
causes.negative.tweets = causes.negative.tweets$Negative_Reason %>% as.vector
# how many reasons?
causes.negative.tweets %>% length

causes.negative.tweets[1:20]
# any repeated reason?
length(unique(causes.negative.tweets))

# since the identified reasons for the negative rewiews are just 10 we simply consider them all and analize the frequencies

causes.negative.tweets.unique = unique(causes.negative.tweets)
causes.negative.tweets.unique


# wordclouds
wordcloud(words=causes.negative.tweets.unique,
          freq=table(causes.negative.tweets),
          max.words = length(causes.negative.tweets.unique),
          colors=brewer.pal(8, "Dark2"), random.order=FALSE,
          use.r.layout = F, scale=c(1,1))
# distribution
barplot(
        prop.table(table(as.factor(causes.negative.tweets))),
        main="Main causes for negative tweets",
        axes=TRUE,
        col=10:(length(causes.negative.tweets)),
        las=2,
    )
```

look the problem from a different perspective
```{r}
# add a column for the length of the tweets
data.raw$TextLength = nchar(data.raw$Text)
summary(data.raw$TextLength)

# there are very short tweets to very long ones; is there any correlation
# with the emerging sentiment??

par(mfrow=c(2,2),cex=.8,main="Distribution
     of TextLength for Sentiments")
# positive
hist(data.raw$TextLength[data.raw$Sentiment=="positive"],freq=T, breaks=100,col=3,xlim=c(12,186))
# neutral
hist(data.raw$TextLength[data.raw$Sentiment=="neutral"],freq=T, breaks=100,col=2,xlim=c(12,186))
# negative
hist(data.raw$TextLength[data.raw$Sentiment=="negative"],freq=T, breaks=100,col=4,xlim=c(12,186))

# by ggplot histogram
ggplot(data.raw, aes(x = TextLength, fill = Sentiment)) +
  theme_bw() +
  geom_histogram(binwidth = 3) +
  labs(y = "Text Count", x = "Length of Text",
       title = "Distribution of Text Lengths with Sentiment Labels")

# No evidence from the histogram, the text length seems 
# to behave the same way indipendently on the caracterization of the tweet

```
Before we move on with a train/test split and the preprocessing step, we must notice that because of how tweetter's tag sistem works it is very common to have words that starts with "@" and are irrelevant because they are simply either the name or the company or the name of another user; for which we already decided to keep track in 'Airline' or simply discard
```{r}
data.raw$Text =  gsub("@([a-zA-Z0-9]|[_])*", "", data.raw$Text)
```
PREPROCESSING:
1) TOKENIZATION
2) LOWER CASING
3) REMOVE STOPWORDS
3) STEMMING
4) MONOGRAM AND 2-GRAMS

We will later consider both BOW and TFIDF metrics to represent the data
```{r}
# create 70/30 % split maintaining
# the proportion of the classes
indexes.split = createDataPartition(data.raw$Sentiment, times=1,
                              p=0.7, list=F)

# train set
train.raw = data.raw[indexes.split,]
# test set
test.raw = data.raw[-indexes.split,]

# check that proportions are correct
prop.table(table(train.raw$Sentiment))
prop.table(table(test.raw$Sentiment))

# 1) TOKENIZATION
train.tokens = tokens(train.raw$Text, what="word",
                      remove_punct = TRUE, remove_symbols = TRUE,
                      remove_numbers = TRUE, remove_separators = TRUE,
                      split_hyphens = TRUE, remove_url = TRUE) 
# 2) LOWER CASING
train.tokens = tokens_tolower(train.tokens)

# 3) REMOVE STOPWORDS
train.tokens = tokens_select(train.tokens, stopwords("en"),
                             selection = "remove")

# 4) STEMMING
train.tokens =tokens_wordstem(train.tokens, language = "english")


# use quanteda class Document-term Frequency Matrix (DFM) 
# document_term_frequency_matrix
# built-in type in quanteda library
train.tokens.dfm = dfm(train.tokens)
# cast it to matrix
train.tokens.matrix = as.matrix(train.tokens.dfm)
# train.tokens.matrix = train.tokens %>% dfm() %>% as.matrix()

dim(train.tokens.matrix)

# let's see the effects of stemming
colnames(train.tokens.matrix)[1:50]
```

##Correspondance Analysis
```{r}
library("FactoMineR")
library("factoextra")
```

```{r}
CA = CA(as.data.frame(t(train.tokens.matrix)))
```

```{r}
# how many components do we need to get 80% of total inertia?
min(which(CA$eig[,3] >= 80.0))
# 2963

CA$svd$U %>% dim
CA$svd$V %>% dim


```



